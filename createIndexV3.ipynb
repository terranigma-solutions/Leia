{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Open and read the config file\n",
    "with open('config.json', 'r') as config_file:\n",
    "    config_data = json.load(config_file)\n",
    "\n",
    "# Retrieve the API key from the config data\n",
    "api_key = config_data['api_key']\n",
    "os.environ['OPENAI_API_KEY'] = api_key"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## logging"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "from llama_index.callbacks import CallbackManager, TokenCountingHandler\n",
    "from llama_index import VectorStoreIndex, SimpleDirectoryReader, ServiceContext\n",
    "\n",
    "# you can set a tokenizer directly, or optionally let it default\n",
    "# to the same tokenizer that was used previously for token counting\n",
    "# NOTE: The tokenizer should be a function that takes in text and returns a list of tokens\n",
    "token_counter = TokenCountingHandler(\n",
    "    tokenizer=tiktoken.encoding_for_model(\"gpt-4\").encode,\n",
    "    verbose=True  # set to true to see usage printed to the console\n",
    "    )\n",
    "callback_manager = CallbackManager([token_counter])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## create Vector Index for Actions\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Load you data into 'Documents' a custom type by LlamaIndex\n",
    "from llama_index import SimpleDirectoryReader\n",
    "\n",
    "documents = SimpleDirectoryReader('./data/Actions', recursive=True).load_data()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### add metadata"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creates a new space for the user. : LeiaActionsCreateSpace\n",
      "changes the background color of the LiquidEarth Workspace. : LeiaActionsSwitchBackgroundColor\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# save control fields in the documents metadata\n",
    "for doc in documents:\n",
    "\n",
    "    # extract the Value of the control from the text with regex. controls are in the format: /nControl: Value/n\n",
    "    contr = re.search(r'(?<=\\ndescription: ).*(?=\\n)', doc.text)\n",
    "    #get the title. it is the first line of the text\n",
    "    title = doc.text.split('\\n')[2]\n",
    "\n",
    "    #check if a control value was found and write it to the metadata\n",
    "    if contr:\n",
    "        doc.metadata['short_description'] = contr.group(0)\n",
    "        doc.metadata['name'] = title\n",
    "        print(doc.metadata['short_description'] + ' : ' + title)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# This is for when building the index from nodes instead Documents:\n",
    "# Nodes are usefull when the same nodes should be part of several indexes\n",
    "from llama_index.node_parser import SimpleNodeParser\n",
    "\n",
    "parser = SimpleNodeParser()\n",
    "\n",
    "nodes = parser.get_nodes_from_documents(documents)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Token Usage: 329\n"
     ]
    }
   ],
   "source": [
    "from llama_index import VectorStoreIndex\n",
    "from llama_index import LangchainEmbedding, ServiceContext\n",
    "\n",
    "service_context = ServiceContext.from_defaults(callback_manager=callback_manager) # use default settings but connect the token logger\n",
    "actions_index = VectorStoreIndex.from_documents(documents, service_context=service_context)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Token Usage: 605\n",
      "Embedding Token Usage: 329\n",
      "Embedding Token Usage: 310\n",
      "Embedding Token Usage: 395\n",
      "Embedding Token Usage: 975\n",
      "Embedding Token Usage: 523\n",
      "Embedding Token Usage: 1458\n",
      "Embedding Token Usage: 811\n",
      "Embedding Token Usage: 257\n",
      "Embedding Token Usage: 835\n",
      "Embedding Token Usage: 681\n",
      "Embedding Token Usage: 540\n",
      "Embedding Token Usage: 728\n",
      "Embedding Token Usage: 365\n",
      "Embedding Token Usage: 404\n",
      "Embedding Token Usage: 280\n",
      "Embedding Token Usage: 548\n",
      "Embedding Token Usage: 692\n",
      "Embedding Token Usage: 263\n",
      "Embedding Token Usage: 537\n",
      "Embedding Token Usage: 454\n",
      "Embedding Token Usage: 799\n",
      "Embedding Token Usage: 326\n",
      "Embedding Token Usage: 371\n",
      "Embedding Token Usage: 1451\n",
      "Embedding Token Usage: 1182\n",
      "Embedding Token Usage: 9062\n",
      "Embedding Token Usage: 412\n",
      "Embedding Token Usage: 931\n",
      "Embedding Token Usage: 1048\n",
      "Embedding Token Usage: 2510\n",
      "Embedding Token Usage: 1103\n",
      "Embedding Token Usage: 4367\n",
      "Embedding Token Usage: 3477\n"
     ]
    }
   ],
   "source": [
    "documents = SimpleDirectoryReader('./data/Other', recursive=True).load_data()\n",
    "\n",
    "\n",
    "# save control fields in the documents metadata\n",
    "for doc in documents:\n",
    "\n",
    "    # extract the Value of the control from the text with regex. controls are in the format: /nControl: Value/n\n",
    "    contr = re.search(r'(?<=\\ndescription: ).*(?=\\n)', doc.text)\n",
    "    #get the title. it is the first line of the text\n",
    "    title = doc.text.split('\\n')[2]\n",
    "\n",
    "    #check if a control value was found and write it to the metadata\n",
    "    if contr:\n",
    "        doc.metadata['short_description'] = contr.group(0)\n",
    "        doc.metadata['name'] = title\n",
    "        print(doc.metadata['short_description'] + ' : ' + title)\n",
    "\n",
    "docu_index = VectorStoreIndex.from_documents(documents, service_context=service_context)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39358\n"
     ]
    }
   ],
   "source": [
    "print(token_counter.total_embedding_token_count)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## save the indexes\n",
    "\n",
    "saves the index under /storage in json format"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "actions_index.storage_context.persist(\"./storage/actions\")\n",
    "docu_index.storage_context.persist(\"./storage/documentation\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
